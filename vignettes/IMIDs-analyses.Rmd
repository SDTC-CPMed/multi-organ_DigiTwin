---
title: "IMIDs analyses"
author: "Martin Smelik, Danuta Gawel, Sandra Lilja"
date: "29/04/2022"
output: 
  md_document:
    variant: markdown_github
---

---
title: "IMIDs analyses"
author: "Martin Smelik, Danuta Gawel, Sandra Lilja"
date: "29/04/2022"
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Meta analysis of 11 IMIDs for Connective pathway analysis and UR prioritization

``` matlab:code
clear all
close all
clc

%% Define main path
InputOutputFiles = '../data/CPA_InputFiles/';

%% Main analyses

% define variables:
savename = 'IMID';
PATHH1 = sprintf('%sPathwayenrichment_results/IMIDs/',InputOutputFiles);
FN = readtable(sprintf('%s/PathFilesDescription_IMIDs.csv',InputOutputFiles));

% read in all pathways, filter significant ones, find all involved genes
% and summarize pathway activation direction:
[AllEnrichedPaths,filesForOverlap] = ReadInIPAPathwayEnrichments(FN,PATHH1);

% calculate jaccard index:
Jaccard = CalculateJaccardIndex(AllEnrichedPaths);

% save to files:
writetable(Jaccard,sprintf('%sJaccardIndex_%s.csv',InputOutputFiles,savename))
writetable(AllEnrichedPaths,sprintf('%sPathInfo_%s.csv',InputOutputFiles,savename))
writetable(FN,sprintf('%sDatasetInfo_%s.csv',InputOutputFiles,savename),'delimiter','\t')
writetable(filesForOverlap,sprintf('%sDieasesPathways_%s.csv',InputOutputFiles,savename),'delimiter','\t')

```

FOLLOWING analyses are in R:

# Connective Pathway Analysis of IMIDs
Similarly to Connective Pathway Analysis of mouse joints and muscle [TODO: REF] we have performed CPA:

```{r, message=FALSE}
source("../R/CPA_UR_rankings_functions.R")

MainPath = "data/CPA_InputFiles/"

# load pre-computed Jaccard index matrix and pathway information plus define name which is to be used to save results:

xx = as.matrix(read.csv(paste(MainPath, 'JaccardIndex_IMID.csv',sep='')))
pathinfo = read.table(paste(MainPath,'PathInfo_IMID.csv',sep=''),sep=',',header=1) 
SAVENAME = 'IMID'

pathinfo = runCPA(xx,pathinfo,SAVENAME,1.78)
# save results to file:
write.table(file=paste(MainPath,'CPA_',SAVENAME,'_all_pathways.txt',sep=''),pathinfo,sep="\t", col.names=T, row.names=F, quote=F)

# count the ratios of pathways showing same and opposing activation pattern in inflamed vs non-inflamed organ:
ratios = count.same.and.opposing.activations(pathinfo)
```

# Overlap of the CPA of IMIDs vs individual IMIDs
In order to get a better overview on which programs and sub-programs of CPA are enriched in indyvidual diseases, we calulated a Fisher Exact Test.
To test if the programs (IMID_P1 and IMID_P2) derived from all analyzed IMIDs overlapped with programs from individual IMIDs in inflamed and non-inflamed organ sites, separately, we performed Fisher’s exact tests (right tailed), using all pathways in connective pathway analysis as a background, followed by correction for multiple testing using the Benjamini-Hochberg procedure. These analyses were repeated for IMID_subprograms (IMID_SPs) and subprograms from individual IMIDs. Disease pathways were defined as all pathways significantly enriched in a particular disease and inflammation state (IPA, p < 0.05). In case two or more datasets were representative of the same disease and condition (for example UC inflamed organs), pathway enrichment p values were combined with Fisher’s method. Enriched pathways were considered those whose combined p < 0.05

```{r, message=FALSE}
# prepare files to check overlap between programs and enriched pathways per IMID:
Dis.Pval = read.table(paste(MainPath,'DieasesPathways_IMID.csv',sep=''),sep='\t',quote = "",header=T)
OverlapingPaths = FindOverlapingPaths(Dis.Pval,pathinfo)

```

TODO: HERE COMES CODE TO PLOT THE OVERLAP: MARTIN HAS USED/ OR RECREATED THE CODE FOR THIS
```{r echo=TRUE, eval = TRUE}
library(ggplot2)

source("../R/plot_overlap.R")
overlap = read.csv('../data/IMIDs_pathway_overlap_with_SPs_reshaped_for_dot_plotALL.txt')

temp_plot <- plot_overlap(overlap)
temp_plot
```

# UR prediction

TODO: Reference UR_enrichment_IMIDs.mlx

# Load libraries
```{python echo=T, results='hide'}
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import openpyxl
```

```{R}
library(reticulate)
library(knitr)
library(cowplot)
library(ggplot2)

```

# Load input
```{python echo=T, results='hide'}
URs_all_diseases = pd.read_table('../data/UR_analysis/UR_predictions_IMIDs_disease_Pvals.txt', sep = ',')
datasets = pd.read_table('../data/UR_analysis/file_names.txt', header = None)
URs = pd.read_table('../data/UR_analysis/URs.txt', header = None)[0]
activity = pd.read_table('../data/UR_analysis/activity.txt', header = None)
translation = pd.read_table('../data/UR_analysis/gene_info.txt', sep = ',')
Datasets_Inf = pd.read_table('../data/UR_analysis/Datasets_Inf.txt', sep = ',', header = None)
Datasets_Noninf = pd.read_table('../data/UR_analysis/Datasets_Noninf.txt', sep = ',', header = None)
path_DEGs = '../data/AllDEGfilesMovedToOneFolder/'
path_z_scores = '../data/UR_analysis/z_scores/ '

```

# Set output paths
```{python}
path_Data_S15 = '../data/UR_analysis/Data S15.xlsx'
path_URs_logFC = '../data/UR_analysis/UR_IMID_summary_logFC.csv'
path_URs_zScore = '../data/UR_analysis/UR_IMID_summary_z.csv'
```


# Preprocess the data
```{python echo=T, results='hide'}



# Subset to only P1 and only those URs that are significant in at least 1 disease
URs_all_diseases = URs_all_diseases[URs_all_diseases['SP'] == '1.6']
IMID_count = list()
for i in range(len(URs_all_diseases)):
    IMID_count.append(sum(URs_all_diseases.iloc[i,8:] < 0.05))
URs_all_diseases = URs_all_diseases[np.array(IMID_count) > 0]

URs_all_diseases = URs_all_diseases.sort_values(by = 'UC_active')
#URs_all_diseases.to_excel(path_Data_S15, header = True, index = False)

URs_all_diseases.head()
```

```{r echo=FALSE}
kable(head(py$URs_all_diseases))
```


```{python echo=T, results='hide'}
# Read data. All output of UR_enrichment_DEGs_as_background.m

#file names:
datasets = datasets.drop(21)
datasets.index = np.array(range(len(datasets)))
datasets = datasets[0]


#if disease is active or not
activity = activity.drop(21)
activity.index = np.array(range(len(activity)))
activity = activity[0]

#Gene translation

#If UR is predicted to be UR in a given dataset for SP1.6
Datasets_Inf.index = URs
Datasets_Inf.columns = datasets[activity == 'yes']
Datasets_Noninf.index = URs
Datasets_Noninf.columns = datasets[activity == 'no']

Datasets_Inf.head()
```

```{r echo=FALSE}
kable(head(py$Datasets_Inf))
```

# Main analyses
```{python echo=T, results='hide'}
i = 0
logFC_list = list()
for dataset in Datasets_Inf.columns:
    data = pd.read_table(path_DEGs + dataset)
    if i in (6,12,15,16):
        if i == 15:
            data = data.rename(columns = {'ORF': 'ENTREZ_GENE_ID'})
        trans = translation[translation['Symbol'].isin(Datasets_Inf.index)][['GeneID','Symbol']]
        data = trans.merge(data, left_on = 'GeneID', right_on ='ENTREZ_GENE_ID')[['Symbol', 'logFC']]
        data = data.rename(columns = {'Symbol': 'Gene.symbol'})
    else:
        if i in (7,20):
            data = data.rename(columns = {'ORF': 'Gene.symbol'})
        if i == 8:
            data = data.rename(columns = {'Gene.Symbol': 'Gene.symbol'})
        if i == 9:
            data = data.rename(columns = {'GENE_SYMBOL': 'Gene.symbol'})
        if i == 13:
            data = data.rename(columns = {'ID': 'Gene.symbol'})
        data = data[data['adj.P.Val'] < 0.05]
        data = data[data['Gene.symbol'].isin(Datasets_Inf.index)]\
        .drop_duplicates('Gene.symbol')[['Gene.symbol', 'logFC']]
    
    data = data.rename(columns = {'logFC': dataset})
    data.index = data['Gene.symbol']
    data.pop('Gene.symbol')    
    logFC_list.append(data)
    i = i+1
    
logFC_Inf = pd.concat(logFC_list, axis = 1)

i = 0
logFC_list = list()
for dataset in Datasets_Noninf.columns:

    data = pd.read_table(path_DEGs + dataset)
    if i == 3:
        data = data.rename(columns = {'ORF': 'Gene.symbol'})
    if i == 8:
        data = data.rename(columns = {'GENE_NAME': 'Gene.symbol'})
    data = data[data['adj.P.Val'] < 0.05]
    data = data[data['Gene.symbol'].isin(Datasets_Inf.index)].drop_duplicates('Gene.symbol')[['Gene.symbol', 'logFC']]
    data = data.rename(columns = {'logFC': dataset})
    data.index = data['Gene.symbol']
    data.pop('Gene.symbol')
    logFC_list.append(data)
    i = i+1
    
logFC_Noninf = pd.concat(logFC_list, axis = 1)

logFC_Inf.head()
```

```{r echo=FALSE}
kable(head(py$logFC_Inf))
```


```{python echo=T, results='hide'}
z_scores_Inf = list()
i = 0
for dataset in Datasets_Inf.columns:
    if i != 12:
        a = pd.read_table(path_z_scores + dataset, sep = ',', index_col = 0)    
        a.columns = [dataset]
        z_scores_Inf.append(a)
    i = i+1
z_scores_Inf = pd.concat(z_scores_Inf, axis = 1)
        
    
z_scores_Noninf = list()
for dataset in Datasets_Noninf.columns:
    a = pd.read_table(path_z_scores + dataset, sep = ',', index_col = 0)    
    a.columns = [dataset]
    z_scores_Noninf.append(a)
z_scores_Noninf = pd.concat(z_scores_Noninf, axis = 1)

z_scores_Inf.head()
```

```{r echo=FALSE}
kable(head(py$z_scores_Inf))
```

```{python echo=T, results='hide'}
Datasets_Noninf_z_score = Datasets_Noninf.copy()
Datasets_Inf_z_score = Datasets_Inf.copy()

i = 0
for dataset in Datasets_Noninf_z_score.columns:
    Datasets_Noninf_z_score.loc[Datasets_Noninf_z_score[dataset]>0,dataset] =\
    z_scores_Noninf[Datasets_Noninf_z_score[dataset]>0][dataset]

for dataset in Datasets_Inf_z_score.columns:
    if i != 12:
        Datasets_Inf_z_score.loc[Datasets_Inf_z_score[dataset]>0,dataset] =\
        z_scores_Inf[Datasets_Inf_z_score[dataset]>0][dataset]
    i = i+1
    
summary = pd.concat((Datasets_Inf_z_score, Datasets_Noninf_z_score), axis = 1)
summary = summary.fillna(0)
summary = summary[summary.sum(axis = 1) != 0]
summary = summary.loc[summary.index.isin(['AR', 'ESR2', 'FAS', 'IFNG', 'IL1A', 'IL1B', 'TLR3', 'TNF'])]
summary.to_csv(path_URs_zScore)
summary.head()
```

```{r echo=FALSE}
kable(head(py$summary))
```

```{python echo=T, results='hide'}
Datasets_Noninf_logFC = Datasets_Noninf.copy()
Datasets_Inf_logFC = Datasets_Inf.copy()

i = 0
for dataset in Datasets_Noninf_logFC.columns:
    Datasets_Noninf_logFC.loc[Datasets_Noninf_logFC[dataset]>0,dataset] =\
    logFC_Noninf[Datasets_Noninf_logFC[dataset]>0][dataset]

for dataset in Datasets_Inf_logFC.columns:
    if i != 12:
        Datasets_Inf_logFC.loc[Datasets_Inf_logFC[dataset]>0,dataset] =\
        logFC_Inf[Datasets_Inf_logFC[dataset]>0][dataset]
    i = i+1
    
summary = pd.concat((Datasets_Inf_logFC, Datasets_Noninf_logFC), axis = 1)
summary = summary.fillna(0)
summary = summary[summary.sum(axis = 1) != 0]
summary = summary.loc[summary.index.isin(['AR', 'ESR2', 'FAS', 'IFNG', 'IL1A', 'IL1B', 'TLR3', 'TNF'])]
summary.to_csv(path_URs_logFC)
summary.head()
```

```{r echo=FALSE}
kable(head(py$summary))
```


#Plot the logFC and z_scores of URs

## URs z score
```{r echo=TRUE, eval = TRUE}
source('../R/plot_zScore.R')
URs_zScore = read.csv('../data/UR_analysis/UR_IMID_summary_z.csv')

temp_plot <- plot_zScore(URs_zScore)
temp_plot


```

## URs logFC

```{R echo=TRUE, eval = TRUE}
source("../R/plot_logFC.R")
URs_logFC = read.csv('../data/UR_analysis/UR_IMID_summary_logFC.csv')

temp_plot <- plot_logFC(URs_logFC)
temp_plot
```



